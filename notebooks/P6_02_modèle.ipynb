{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1757b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:53:06.563000Z",
     "start_time": "2021-07-02T08:53:05.052215Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "num_channels = 3\n",
    "num_classes = 120\n",
    "project_path ='Documents/OC_Ingenieur_ML/P6_Classez_des_images/'\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import Model,callbacks\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.layers[-2].output\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 10 classes\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Figer tous les poids\n",
    "for layer in new_model.layers[:]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c9a4eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:53:07.555286Z",
     "start_time": "2021-07-02T08:53:06.571872Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fedecabre\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               491640    \n",
      "=================================================================\n",
      "Total params: 134,752,184\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,752,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%cd\n",
    "# Compiler le modèle\n",
    "new_model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "new_model.load_weights(project_path+'models/model120_weights.h5')\n",
    "new_model.save(project_path+'models/model120.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "808f767f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:24:04.783681Z",
     "start_time": "2021-07-02T09:24:04.296102Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20579 images belonging to 120 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'n02085620-Chihuahua',\n",
       " 1: 'n02085782-Japanese_spaniel',\n",
       " 2: 'n02085936-Maltese_dog',\n",
       " 3: 'n02086079-Pekinese',\n",
       " 4: 'n02086240-Shih-Tzu',\n",
       " 5: 'n02086646-Blenheim_spaniel',\n",
       " 6: 'n02086910-papillon',\n",
       " 7: 'n02087046-toy_terrier',\n",
       " 8: 'n02087394-Rhodesian_ridgeback',\n",
       " 9: 'n02088094-Afghan_hound',\n",
       " 10: 'n02088238-basset',\n",
       " 11: 'n02088364-beagle',\n",
       " 12: 'n02088466-bloodhound',\n",
       " 13: 'n02088632-bluetick',\n",
       " 14: 'n02089078-black-and-tan_coonhound',\n",
       " 15: 'n02089867-Walker_hound',\n",
       " 16: 'n02089973-English_foxhound',\n",
       " 17: 'n02090379-redbone',\n",
       " 18: 'n02090622-borzoi',\n",
       " 19: 'n02090721-Irish_wolfhound',\n",
       " 20: 'n02091032-Italian_greyhound',\n",
       " 21: 'n02091134-whippet',\n",
       " 22: 'n02091244-Ibizan_hound',\n",
       " 23: 'n02091467-Norwegian_elkhound',\n",
       " 24: 'n02091635-otterhound',\n",
       " 25: 'n02091831-Saluki',\n",
       " 26: 'n02092002-Scottish_deerhound',\n",
       " 27: 'n02092339-Weimaraner',\n",
       " 28: 'n02093256-Staffordshire_bullterrier',\n",
       " 29: 'n02093428-American_Staffordshire_terrier',\n",
       " 30: 'n02093647-Bedlington_terrier',\n",
       " 31: 'n02093754-Border_terrier',\n",
       " 32: 'n02093859-Kerry_blue_terrier',\n",
       " 33: 'n02093991-Irish_terrier',\n",
       " 34: 'n02094114-Norfolk_terrier',\n",
       " 35: 'n02094258-Norwich_terrier',\n",
       " 36: 'n02094433-Yorkshire_terrier',\n",
       " 37: 'n02095314-wire-haired_fox_terrier',\n",
       " 38: 'n02095570-Lakeland_terrier',\n",
       " 39: 'n02095889-Sealyham_terrier',\n",
       " 40: 'n02096051-Airedale',\n",
       " 41: 'n02096177-cairn',\n",
       " 42: 'n02096294-Australian_terrier',\n",
       " 43: 'n02096437-Dandie_Dinmont',\n",
       " 44: 'n02096585-Boston_bull',\n",
       " 45: 'n02097047-miniature_schnauzer',\n",
       " 46: 'n02097130-giant_schnauzer',\n",
       " 47: 'n02097209-standard_schnauzer',\n",
       " 48: 'n02097298-Scotch_terrier',\n",
       " 49: 'n02097474-Tibetan_terrier',\n",
       " 50: 'n02097658-silky_terrier',\n",
       " 51: 'n02098105-soft_coated_wheaten_terrier',\n",
       " 52: 'n02098286-West_Highland_white_terrier',\n",
       " 53: 'n02098413-Lhasa',\n",
       " 54: 'n02099267-flat_coated_retriever',\n",
       " 55: 'n02099429-curly_coated_retriever',\n",
       " 56: 'n02099601-golden_retriever',\n",
       " 57: 'n02099712-Labrador_retriever',\n",
       " 58: 'n02099849-Chesapeake_Bay_retriever',\n",
       " 59: 'n02100236-German_short-haired_pointer',\n",
       " 60: 'n02100583-vizsla',\n",
       " 61: 'n02100735-English_setter',\n",
       " 62: 'n02100877-Irish_setter',\n",
       " 63: 'n02101006-Gordon_setter',\n",
       " 64: 'n02101388-Brittany_spaniel',\n",
       " 65: 'n02101556-clumber',\n",
       " 66: 'n02102040-English_springer',\n",
       " 67: 'n02102177-Welsh_springer_spaniel',\n",
       " 68: 'n02102318-cocker_spaniel',\n",
       " 69: 'n02102480-Sussex_spaniel',\n",
       " 70: 'n02102973-Irish_water_spaniel',\n",
       " 71: 'n02104029-kuvasz',\n",
       " 72: 'n02104365-schipperke',\n",
       " 73: 'n02105056-groenendael',\n",
       " 74: 'n02105162-malinois',\n",
       " 75: 'n02105251-briard',\n",
       " 76: 'n02105412-kelpie',\n",
       " 77: 'n02105505-komondor',\n",
       " 78: 'n02105641-Old_English_sheepdog',\n",
       " 79: 'n02105855-Shetland_sheepdog',\n",
       " 80: 'n02106030-collie',\n",
       " 81: 'n02106166-Border_collie',\n",
       " 82: 'n02106382-Bouvier_des_Flandres',\n",
       " 83: 'n02106550-Rottweiler',\n",
       " 84: 'n02106662-German_shepherd',\n",
       " 85: 'n02107142-Doberman',\n",
       " 86: 'n02107312-miniature_pinscher',\n",
       " 87: 'n02107574-Greater_Swiss_Mountain_dog',\n",
       " 88: 'n02107683-Bernese_mountain_dog',\n",
       " 89: 'n02107908-Appenzeller',\n",
       " 90: 'n02108000-EntleBucher',\n",
       " 91: 'n02108089-boxer',\n",
       " 92: 'n02108422-bull_mastiff',\n",
       " 93: 'n02108551-Tibetan_mastiff',\n",
       " 94: 'n02108915-French_bulldog',\n",
       " 95: 'n02109047-Great_Dane',\n",
       " 96: 'n02109525-Saint_Bernard',\n",
       " 97: 'n02109961-Eskimo_dog',\n",
       " 98: 'n02110063-malamute',\n",
       " 99: 'n02110185-Siberian_husky',\n",
       " 100: 'n02110627-affenpinscher',\n",
       " 101: 'n02110806-basenji',\n",
       " 102: 'n02110958-pug',\n",
       " 103: 'n02111129-Leonberg',\n",
       " 104: 'n02111277-Newfoundland',\n",
       " 105: 'n02111500-Great_Pyrenees',\n",
       " 106: 'n02111889-Samoyed',\n",
       " 107: 'n02112018-Pomeranian',\n",
       " 108: 'n02112137-chow',\n",
       " 109: 'n02112350-keeshond',\n",
       " 110: 'n02112706-Brabancon_griffon',\n",
       " 111: 'n02113023-Pembroke',\n",
       " 112: 'n02113186-Cardigan',\n",
       " 113: 'n02113624-toy_poodle',\n",
       " 114: 'n02113712-miniature_poodle',\n",
       " 115: 'n02113799-standard_poodle',\n",
       " 116: 'n02113978-Mexican_hairless',\n",
       " 117: 'n02115641-dingo',\n",
       " 118: 'n02115913-dhole',\n",
       " 119: 'n02116738-African_hunting_dog'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pickle\n",
    "\n",
    "crop_images_folders_path = project_path+\"data/Cropped/\"\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "generator = datagen.flow_from_directory(crop_images_folders_path,\n",
    "                                                target_size=(image_size, image_size),\n",
    "                                                batch_size=32,\n",
    "                                                subset=\"training\",\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "train_size = train_generator.n\n",
    "races = generator.class_indices.keys()\n",
    "races_dict = generator.class_indices\n",
    "races_invert_dict = {v: k for k, v in races_dict.items()}\n",
    "\n",
    "races_invert_dict_file = open(project_path+\"models/races_invert_dict.pkl\", \"wb\")\n",
    "pickle.dump(races_invert_dict, races_invert_dict_file)\n",
    "races_invert_dict_file.close()\n",
    "\n",
    "races_invert_dict_file = open(project_path+\"models/races_invert_dict.pkl\", \"rb\")\n",
    "races_invert_dict = pickle.load(races_invert_dict_file)\n",
    "races_invert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "545d02cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:12.041114Z",
     "start_time": "2021-07-02T09:37:11.894082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lhasa 0.50763047\n",
      "Pekinese 0.4372862\n",
      "Shih 0.053308826\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image_path = project_path+'data/COCO/coco.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "image = image.reshape(1, 224, 224, 3)\n",
    "prediction = new_model.predict(image)[0]\n",
    "top3 = prediction.argsort()[::-1][:3]\n",
    "top3_list = []\n",
    "for i in top3:\n",
    "    print(races_invert_dict[i].split('-')[1],prediction[i])\n",
    "    top3_list.append(races_invert_dict[i].split('-')[1]+\" = \"+str(prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f5a062f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T09:37:20.225210Z",
     "start_time": "2021-07-02T09:37:20.222468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lhasa = 0.50763047', 'Pekinese = 0.4372862', 'Shih = 0.053308826']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30659db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
